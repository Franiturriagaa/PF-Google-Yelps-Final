{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Carga de datos (10% del archivo merged DF's de la combinacion de Yelp business,review y tip)\n",
    "df = pd.read_csv('rep_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>main category</th>\n",
       "      <th>tip_text</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rev_yelp_sentiment</th>\n",
       "      <th>tip_yelp_sentiment</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>cluster</th>\n",
       "      <th>combined_score</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>tip_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cGX-1IUwXOjkUqZbkKYcjw</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.950917</td>\n",
       "      <td>-75.162971</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Awesome salad bar with good quality cheeses, v...</td>\n",
       "      <td>We went for lunch on a wed afternoon. It defin...</td>\n",
       "      <td>0.194722</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.597361</td>\n",
       "      <td>0</td>\n",
       "      <td>5.792083</td>\n",
       "      <td>0.194722</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ueAkLzWFFTzQkq3jzyBlnA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955392</td>\n",
       "      <td>-75.154698</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>It's such an addiction..</td>\n",
       "      <td>I actually still love this place...probably be...</td>\n",
       "      <td>0.371469</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.185735</td>\n",
       "      <td>0</td>\n",
       "      <td>4.557204</td>\n",
       "      <td>0.371469</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tMtI6ECD6hwM-nFp2kXLKQ</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.954605</td>\n",
       "      <td>-75.156209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Food</td>\n",
       "      <td>I love their fresh watermelon drink!</td>\n",
       "      <td>Thanks to bubble tea reviews on Yelp I read ab...</td>\n",
       "      <td>0.382248</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.409874</td>\n",
       "      <td>0</td>\n",
       "      <td>5.229622</td>\n",
       "      <td>0.382248</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q-zV08jt6U-q05SMEuQJAQ</td>\n",
       "      <td>19148</td>\n",
       "      <td>39.914107</td>\n",
       "      <td>-75.148727</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Love it!\\nLove it!\\nGood food</td>\n",
       "      <td>Simply based on the cheesesteak.\\n\\nCheesestea...</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.433150</td>\n",
       "      <td>0</td>\n",
       "      <td>5.299451</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EzQpL3jNNGlUzeR6n3uevg</td>\n",
       "      <td>19130</td>\n",
       "      <td>39.968551</td>\n",
       "      <td>-75.174874</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bars</td>\n",
       "      <td>Delicious pierogi pizza!</td>\n",
       "      <td>Living nearby, I had always wanted to enjoy Re...</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.497273</td>\n",
       "      <td>0</td>\n",
       "      <td>4.991818</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  postal_code   latitude  longitude  stars   \n",
       "0  cGX-1IUwXOjkUqZbkKYcjw        19107  39.950917 -75.162971    4.0  \\\n",
       "1  ueAkLzWFFTzQkq3jzyBlnA        19107  39.955392 -75.154698    4.0   \n",
       "2  tMtI6ECD6hwM-nFp2kXLKQ        19107  39.954605 -75.156209    4.0   \n",
       "3  q-zV08jt6U-q05SMEuQJAQ        19148  39.914107 -75.148727    4.0   \n",
       "4  EzQpL3jNNGlUzeR6n3uevg        19130  39.968551 -75.174874    3.5   \n",
       "\n",
       "  main category                                           tip_text   \n",
       "0   Restaurants  Awesome salad bar with good quality cheeses, v...  \\\n",
       "1   Restaurants                           It's such an addiction..   \n",
       "2          Food               I love their fresh watermelon drink!   \n",
       "3   Restaurants                      Love it!\\nLove it!\\nGood food   \n",
       "4          Bars                           Delicious pierogi pizza!   \n",
       "\n",
       "                                         review_text  rev_yelp_sentiment   \n",
       "0  We went for lunch on a wed afternoon. It defin...            0.194722  \\\n",
       "1  I actually still love this place...probably be...            0.371469   \n",
       "2  Thanks to bubble tea reviews on Yelp I read ab...            0.382248   \n",
       "3  Simply based on the cheesesteak.\\n\\nCheesestea...            0.216300   \n",
       "4  Living nearby, I had always wanted to enjoy Re...           -0.005455   \n",
       "\n",
       "   tip_yelp_sentiment  avg_sentiment  cluster  combined_score   \n",
       "0              1.0000       0.597361        0        5.792083  \\\n",
       "1              0.0000       0.185735        0        4.557204   \n",
       "2              0.4375       0.409874        0        5.229622   \n",
       "3              0.6500       0.433150        0        5.299451   \n",
       "4              1.0000       0.497273        0        4.991818   \n",
       "\n",
       "   review_sentiment  tip_sentiment  \n",
       "0          0.194722         1.0000  \n",
       "1          0.371469         0.0000  \n",
       "2          0.382248         0.4375  \n",
       "3          0.216300         0.6500  \n",
       "4         -0.005455         1.0000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Analisis de Sentimiento review_text and tip_text\n",
    "def analyze_sentiment(text):\n",
    "    if pd.isnull(text):\n",
    "        return 0  # 0 si no hay texto (neutro)\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Aplicar analyze_sentiment\n",
    "df['review_sentiment'] = df['review_text'].apply(analyze_sentiment)\n",
    "df['tip_sentiment'] = df['tip_text'].apply(analyze_sentiment)\n",
    "\n",
    "# 3. Combinar puntajes\n",
    "df['avg_sentiment'] = df[['review_sentiment', 'tip_sentiment']].mean(axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Agrupacion por cluster en Latitud y longitud\n",
    "X_geo = df[['latitude', 'longitude']]\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_geo)\n",
    "\n",
    "# 5. Combinar puntaje por stars y analisis de sentimiento (multiplicado por 3 para igualar importancia)\n",
    "df['combined_score'] = df['stars'] + df['avg_sentiment']*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00041758801372781493\n",
      "Evalucion de importancia:\n",
      "               importancia\n",
      "stars             0.555262\n",
      "avg_sentiment     0.444651\n",
      "postal_code       0.000032\n",
      "longitude         0.000031\n",
      "latitude          0.000025\n"
     ]
    }
   ],
   "source": [
    "# 6. Machine Learning Training/Testing\n",
    "# Variables usadas:\n",
    "X = df[['latitude', 'longitude', 'stars', 'avg_sentiment', 'postal_code']]\n",
    "y = df['combined_score']\n",
    "\n",
    "# 7. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 8. Rescalar datos \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 9. Modelo XGBoost para ajuste de hiperparametros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 10. Evaluacion del modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "\n",
    "# 11. Contribucion de variables\n",
    "feature_importances = pd.DataFrame(best_model.feature_importances_, index=X.columns, columns=['importancia']).sort_values('importancia', ascending=False)\n",
    "print(\"Evaluacion de importancia:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Categorias - Puntaje:\n",
      "1. Pets -  4.93\n",
      "2. Active Life -  4.79\n",
      "3. Food -  4.74\n",
      "4. Shopping -  4.61\n",
      "5. Beauty & Spas -  4.53\n"
     ]
    }
   ],
   "source": [
    "# 12. Agrupar negocios por 'main category' y cluster, calculo de puntaje promedio\n",
    "df_grouped = df.groupby(['main category', 'cluster']).agg({\n",
    "    'combined_score': 'mean',   \n",
    "    'stars': 'mean',            \n",
    "    'avg_sentiment': 'mean',    \n",
    "    'business_id': 'count',     \n",
    "    'latitude': 'mean',         \n",
    "    'longitude': 'mean',        \n",
    "    'postal_code': 'first'      \n",
    "}).reset_index()\n",
    "\n",
    "# 13. Encontrar las 5 top categorias\n",
    "top_5_categories = df_grouped.groupby('main category').agg({\n",
    "    'combined_score': 'mean'   \n",
    "}).reset_index().nlargest(5, 'combined_score')\n",
    "\n",
    "top_5_categories = top_5_categories.reset_index(drop=True)\n",
    "\n",
    "# Imprimir las 5 top categorias en orden de puntaje\n",
    "print(\"Top 5 Categorias - Puntaje:\")\n",
    "for i, row in top_5_categories.iterrows():\n",
    "    print(f\"{i+1}. {row['main category']} -  {row['combined_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Ubicaciones por categoria:Pets:\n",
      "  main category   latitude  longitude  postal_code\n",
      "1          Pets  39.903348 -75.228662        19153\n",
      "2          Pets  39.942996 -75.152209        19107\n"
     ]
    }
   ],
   "source": [
    "# 14. Distancia Haversine para evitar que las 2 ubicaciones sean iguales\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    d_lat = np.radians(lat2 - lat1)\n",
    "    d_lon = np.radians(lon2 - lon1)\n",
    "    a = np.sin(d_lat / 2) ** 2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(d_lon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c * 1000  # Convert to meters\n",
    "\n",
    "# 15. Agrupacion de ubicacion segun la restriccion de distancia (min_distance)\n",
    "def recommend_top_2_locations_for_category_with_distance_constraint(category, min_distance_meters=1000):\n",
    "    category_data = df_grouped[df_grouped['main category'] == category]\n",
    "    top_2_locations = category_data.nlargest(5, 'combined_score')  \n",
    "    \n",
    "    loc1 = top_2_locations.iloc[0]\n",
    "    valid_locations = [loc1]\n",
    "    \n",
    "    for i in range(1, len(top_2_locations)):\n",
    "        loc2 = top_2_locations.iloc[i]\n",
    "        distance = haversine_distance(loc1['latitude'], loc1['longitude'], loc2['latitude'], loc2['longitude'])\n",
    "        if distance > min_distance_meters:\n",
    "            valid_locations.append(loc2)\n",
    "            if len(valid_locations) == 2:\n",
    "                break\n",
    "    \n",
    "    return pd.DataFrame(valid_locations)\n",
    "\n",
    "# 16. Imprimir 2 posibles ubicaciones\n",
    "category = input(\"Ingrese una categoria de las indicadas (e.g., 'Restaurant', 'Coffee Shop', etc.): \")\n",
    "top_2_locations = recommend_top_2_locations_for_category_with_distance_constraint(category, min_distance_meters=1000)\n",
    "# Reiniciar los índices para que comiencen en 1 y no en los índices originales\n",
    "top_2_locations = top_2_locations.reset_index(drop=True)\n",
    "\n",
    "# Mostrar las ubicaciones con el índice ajustado\n",
    "print(f\"Top 2 Ubicaciones por categoria:{category}:\")\n",
    "top_2_locations.index += 1  # Ajustar el índice para que empiece desde 1\n",
    "print(top_2_locations[['main category', 'latitude', 'longitude', 'postal_code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "\n",
    "## ANALISIS DE METRICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Cuadratico Medio (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00041758801372781493\n"
     ]
    }
   ],
   "source": [
    "# Calculo Error Cuadratico Medio en Test (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBS: Un bajo valor de MSE implica que las predicciones son cercanas al valor real, buena precision y los datos en la muestra son consistentes puesto que este parametro es muy suceptible a outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared: 0.9996319893288079\n",
      "Test R-squared: 0.9995957937342933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_train_pred = best_model.predict(X_train_scaled)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "print(f\"Train R-squared: {train_r2}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBS: Se pensaria que este modelo en particular esta sobre entrenado ya que el Train R^2 es cercano a 1, sin embargo el Test R^2 es igualmente alto cercano a 1. Al ambos ser similares y proximos a 1, indica que el modelo esta generalizando bien al menos con la muestra tomada para el ensayo que es un 10% al azar del dataframe original que resulta de hacer merge de Yelp business, review y tip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion por: Validacion Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje Cross-validation R²: [0.99802881 0.99815938 0.99822092]\n",
      "Media de la Cross-validation R²: 0.998136371919648\n",
      "Desviación estándar de la Cross-validation R²: 8.009874575524885e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Parametros para la validacion\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=50,     # Numero de arboles\n",
    "    max_depth=3,         # profundidad de arboles\n",
    "    learning_rate=0.1,   # Tasa de aprendizaje moderado\n",
    "    random_state=42,     # Aleatoriedad\n",
    "    n_jobs=-1            # Usar todos los nucleos para el analisis\n",
    ")\n",
    "\n",
    "# Desempeno de la validacion K-fold= 3 (cv=3 para optimizar el uso de memoria y tiempo de analisis)\n",
    "cv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, cv=3, scoring='r2')\n",
    "\n",
    "# Cálculo de la desviación estándar\n",
    "std_dev = np.std(cv_scores)\n",
    "\n",
    "print(f\"Puntaje Cross-validation R²: {cv_scores}\")\n",
    "print(f\"Media de la Cross-validation R²: {np.mean(cv_scores)}\")\n",
    "print(f\"Desviación estándar de la Cross-validation R²: {std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBS: Metodo usado para evaluar la variabilidad y la confiabilidad de modelos de ML. Entre mas altos y cercanos sean los valores de validacion, mejor el desempeño. Ya que los 3 valores de la validacion son consistentes y similares a lo largo de la muestra, indica que es capaz de generalizar sin estar sobre entrenado y con una baja desviacion estandar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
